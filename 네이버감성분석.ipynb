{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "네이버감성분석.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNrPnK+oBZVjLQ1XBVYpkGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InChil2/cakd3/blob/main/%EB%84%A4%EC%9D%B4%EB%B2%84%EA%B0%90%EC%84%B1%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvV1ur-5ALp5",
        "outputId": "303923a2-610f-4b0a-da88-6bff54cc9187"
      },
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "my_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', my_path)\n",
        "sys.path.insert(0,my_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62-4DRLnAYrb",
        "outputId": "baae94c3-507d-4ea2-c980-164a27c1be19"
      },
      "source": [
        "!pip install --target=$my_path \"jpype1<1.1\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jpype1<1.1\n",
            "  Downloading JPype1-1.0.2-cp37-cp37m-manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 7.5 MB/s \n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: typing-extensions, jpype1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\u001b[0m\n",
            "Successfully installed jpype1-1.0.2 typing-extensions-3.10.0.2\n",
            "\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 566, in move\n",
            "    os.rename(src, real_dst)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pip-target-zscqr5hz/lib/python/JPype1-1.0.2.dist-info' -> '/content/notebooks/JPype1-1.0.2.dist-info'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 450, in run\n",
            "    options.target_dir, target_temp_dir, options.upgrade\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 509, in _handle_target_dir\n",
            "    target_item_dir\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 577, in move\n",
            "    symlinks=True)\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 324, in copytree\n",
            "    os.makedirs(dst)\n",
            "  File \"/usr/lib/python3.7/os.py\", line 223, in makedirs\n",
            "    mkdir(name, mode)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/notebooks/JPype1-1.0.2.dist-info'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PNAzgDJWCw_-",
        "outputId": "8e8e38f6-ea6a-4266-fb29-d313dd0052d9"
      },
      "source": [
        "!pip install --target=$my_path konlpy"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Using cached konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading tweepy-3.10.0-py2.py3-none-any.whl (30 kB)\n",
            "Collecting colorama\n",
            "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting numpy>=1.6\n",
            "  Downloading numpy-1.21.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 144 kB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "  Using cached beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "Collecting lxml>=4.1.0\n",
            "  Downloading lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 48.6 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Using cached JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "Collecting typing-extensions\n",
            "  Using cached typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting six>=1.10.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting requests[socks]>=2.11.1\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 610 kB/s \n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 71.9 MB/s \n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 76.4 MB/s \n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 78.3 MB/s \n",
            "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
            "  Downloading charset_normalizer-2.0.4-py3-none-any.whl (36 kB)\n",
            "Collecting PySocks!=1.5.7,>=1.5.6\n",
            "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests, PySocks, oauthlib, typing-extensions, six, requests-oauthlib, tweepy, numpy, lxml, JPype1, colorama, beautifulsoup4, konlpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.2 which is incompatible.\n",
            "tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed JPype1-1.3.0 PySocks-1.7.1 beautifulsoup4-4.6.0 certifi-2021.5.30 charset-normalizer-2.0.4 colorama-0.4.4 idna-3.2 konlpy-0.5.2 lxml-4.6.3 numpy-1.21.2 oauthlib-3.1.1 requests-2.26.0 requests-oauthlib-1.3.0 six-1.16.0 tweepy-3.10.0 typing-extensions-3.10.0.2 urllib3-1.26.6\n",
            "\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 566, in move\n",
            "    os.rename(src, real_dst)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pip-target-j0lxixpx/lib/python/urllib3' -> '/content/notebooks/urllib3'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 450, in run\n",
            "    options.target_dir, target_temp_dir, options.upgrade\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 509, in _handle_target_dir\n",
            "    target_item_dir\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 577, in move\n",
            "    symlinks=True)\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 324, in copytree\n",
            "    os.makedirs(dst)\n",
            "  File \"/usr/lib/python3.7/os.py\", line 223, in makedirs\n",
            "    mkdir(name, mode)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/notebooks/urllib3'\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "socks"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "-C5PVPMcA4KJ",
        "outputId": "d91640e6-b30f-4c3f-ebb1-4388ebfa8fb4"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/cakd3_colab/textmining/dataset/ratings_train.txt',sep='\\t')\n",
        "train_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qVJtnA8Bihq",
        "outputId": "7eab4db6-b705-44b3-d040-88a2c9a2e8d6"
      },
      "source": [
        "train_df['label'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    75173\n",
              "1    74827\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBmKVxH0Bo43"
      },
      "source": [
        "import re\n",
        "\n",
        "train_df = train_df.fillna(' ')\n",
        "\n",
        "train_df['document'] = train_df['document'].apply(lambda x : re.sub(r'\\d+',' ',x))\n",
        "\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/cakd3_colab/textmining/dataset/ratings_test.txt',sep='\\t')\n",
        "test_df= test_df.fillna(' ')\n",
        "test_df['document'] = test_df['document'].apply(lambda x : re.sub(r'\\d+',' ',x))\n",
        "\n",
        "train_df.drop('id',axis=1, inplace=True)\n",
        "test_df.drop('id',axis=1, inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhZDGAJ1Coht"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()\n",
        "def ok_tokenizer(text):\n",
        "    tokens_ko = okt.morphs(text)\n",
        "    return tokens_ko"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxSlKAgSDUe1",
        "outputId": "9e03c28d-3ae4-4d80-e7fb-7975d5a0a5d9"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "tfidf_vect = TfidfVectorizer(tokenizer=ok_tokenizer,ngram_range=(1,2),min_df=3,max_df=0.9)\n",
        "tfidf_vect.fit(train_df['document'])\n",
        "tfidf_matrix_train = tfidf_vect.transform(train_df['document'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxzjH5FcFD9r"
      },
      "source": [
        "[과제]\n",
        "GridSearchCV를 이용하여 모델리 및 평가를 아래와 같이 수행하세요/\n",
        "  - 로지스틱 리그레션,'C':[1,3.5,4.5,5.5,10]\n",
        "  - cv=3, scoring='accuracy',verbose=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIVR6ZRGEMsq"
      },
      "source": [
        "lg_clf = LogisticRegression(random_state=0)\n",
        "params = {'C':[1,3.5,4.5,5.5,10]}\n",
        "gridcv = GridSearchCV(lg_clf,param_grid=params,cv=3,scoring='accuracy',verbose=1)\n",
        "gridcv.fit(tfidf_matrix_train,train_df['label'])\n",
        "print(grid_cv.best_params_,round(grid_cv.best_score_,4))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}